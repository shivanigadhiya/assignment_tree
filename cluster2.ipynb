{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: What is Hierarchical Clustering and How is it Different from Other Clustering Techniques?\n",
    "Hierarchical clustering is a method that builds a hierarchy of clusters by either merging smaller clusters into larger ones (agglomerative) or splitting larger clusters into smaller ones (divisive). Unlike K-Means, hierarchical clustering does not require specifying the number of clusters (K) beforehand and produces a tree-like structure (dendrogram) that shows relationships between clusters.\n",
    "\n",
    "📌 Key Differences from Other Clustering Techniques:\n",
    "\n",
    "Feature\tHierarchical Clustering\tK-Means Clustering\tDBSCAN\n",
    "Number of Clusters\tNot predefined\tPredefined (K)\tNot required\n",
    "Cluster Shape\tAny shape\tMostly spherical\tArbitrary\n",
    "Scalability\tSlow for large data\tFast for large data\tSlower than K-Means\n",
    "Handles Noise\tLimited\tPoorly\tYes\n",
    "Output Structure\tDendrogram (Tree)\tFixed K clusters\tDensity-based\n",
    "Q2: What are the Two Main Types of Hierarchical Clustering Algorithms?\n",
    "There are two main types of hierarchical clustering:\n",
    "\n",
    "Agglomerative Hierarchical Clustering (Bottom-Up Approach)\n",
    "\n",
    "Starts with each data point as its own cluster.\n",
    "Merges the closest clusters iteratively until only one cluster remains.\n",
    "Commonly used method due to simplicity.\n",
    "🔹 Example: Merging customers based on purchase behavior.\n",
    "\n",
    "Divisive Hierarchical Clustering (Top-Down Approach)\n",
    "\n",
    "Starts with one large cluster containing all data points.\n",
    "Splits clusters recursively until each point is its own cluster.\n",
    "Less common due to higher computational complexity.\n",
    "🔹 Example: Splitting species based on genetic characteristics.\n",
    "\n",
    "Q3: How to Determine the Distance Between Two Clusters in Hierarchical Clustering?\n",
    "Cluster distance is calculated using linkage methods, which define how clusters are merged:\n",
    "\n",
    "Linkage Type\tDefinition\n",
    "Single Linkage\tDistance between the closest points of two clusters. (Leads to elongated clusters)\n",
    "Complete Linkage\tDistance between the farthest points of two clusters. (Encourages compact clusters)\n",
    "Average Linkage\tMean distance between all points in two clusters. (Balanced approach)\n",
    "Centroid Linkage\tDistance between the centroids (means) of two clusters.\n",
    "Ward’s Method\tMinimizes variance within clusters (often gives best results).\n",
    "📌 Common Distance Metrics Used:\n",
    "\n",
    "Euclidean Distance (Default) → \n",
    "𝑑\n",
    "(\n",
    "𝐴\n",
    ",\n",
    "𝐵\n",
    ")\n",
    "=\n",
    "∑\n",
    "(\n",
    "𝐴\n",
    "𝑖\n",
    "−\n",
    "𝐵\n",
    "𝑖\n",
    ")\n",
    "2\n",
    "d(A,B)= \n",
    "∑(A \n",
    "i\n",
    "​\n",
    " −B \n",
    "i\n",
    "​\n",
    " ) \n",
    "2\n",
    " \n",
    "​\n",
    " \n",
    "Manhattan Distance → \n",
    "𝑑\n",
    "(\n",
    "𝐴\n",
    ",\n",
    "𝐵\n",
    ")\n",
    "=\n",
    "∑\n",
    "∣\n",
    "𝐴\n",
    "𝑖\n",
    "−\n",
    "𝐵\n",
    "𝑖\n",
    "∣\n",
    "d(A,B)=∑∣A \n",
    "i\n",
    "​\n",
    " −B \n",
    "i\n",
    "​\n",
    " ∣\n",
    "Cosine Similarity → Measures angle between vectors\n",
    "Q4: How to Determine the Optimal Number of Clusters in Hierarchical Clustering?\n",
    "Since hierarchical clustering does not require K beforehand, you determine the optimal number after constructing the dendrogram.\n",
    "\n",
    "🔹 Common Methods to Find Optimal Clusters:\n",
    "\n",
    "Dendrogram Cutting:\n",
    "\n",
    "Find the largest vertical gap in the dendrogram without merging clusters too soon.\n",
    "Draw a horizontal line where the longest branch split occurs.\n",
    "Silhouette Score:\n",
    "\n",
    "Measures how well a point fits into its assigned cluster.\n",
    "Higher values indicate better clustering quality.\n",
    "Elbow Method on Linkage Distances:\n",
    "\n",
    "Plot intra-cluster distances vs. number of clusters.\n",
    "Find the \"elbow\" where the distance stops decreasing significantly.\n",
    "Q5: What are Dendrograms and How Are They Useful?\n",
    "A dendrogram is a tree-like diagram that visualizes hierarchical clustering results.\n",
    "\n",
    "📌 Key Insights from Dendrograms:\n",
    "\n",
    "Shows relationships between clusters.\n",
    "Helps identify the best number of clusters.\n",
    "Reveals outliers (long branches that don't merge early).\n",
    "🔹 Example: Customer Segmentation\n",
    "\n",
    "A dendrogram groups customers by purchasing behavior.\n",
    "Cutting at an appropriate level provides optimal customer segments.\n",
    "Q6: Can Hierarchical Clustering Be Used for Both Numerical and Categorical Data?\n",
    "✅ Yes, but the distance metrics must be adapted:\n",
    "\n",
    "Data Type\tCommon Distance Metric\n",
    "Numerical Data\tEuclidean, Manhattan, Cosine Similarity\n",
    "Categorical Data\tJaccard Similarity, Hamming Distance\n",
    "Mixed Data\tGower’s Distance (Handles categorical + numerical)\n",
    "📌 Example:\n",
    "\n",
    "Numerical (Age, Income): Use Euclidean Distance.\n",
    "Categorical (Gender, Product Category): Use Jaccard Similarity.\n",
    "Mixed Data (Age + Product Category): Use Gower’s Distance.\n",
    "Q7: How to Use Hierarchical Clustering to Detect Outliers?\n",
    "Hierarchical clustering helps detect outliers by identifying data points that merge late in the dendrogram.\n",
    "\n",
    "🔹 Steps to Detect Outliers:\n",
    "\n",
    "Construct a dendrogram using hierarchical clustering.\n",
    "Identify points that merge at extreme distances.\n",
    "Points that remain isolated for long are likely outliers.\n",
    "📌 Example: Fraud Detection\n",
    "\n",
    "In credit card transactions, outliers might be isolated purchases that merge only at high distances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
